========[WOCSA]X[C’estVraiCa]==============================================

# Table of Contents
1. [Introduction (20-30 min)](#introduction-20-30-min) 
2. [Activity 1: Images FactCheck (30-40 min)](#activity-1-images-factcheck-30-40-min)
3. [Activity 2: Articles FactCheck (45-60 min)](#activity-2-articles-factcheck-45-60-min)
4. [Conclusion (20-30 min)](#conclusion-20-30-min)

---

# Introduction (20-30 min)

## Objective:
Raise participants' awareness of the importance of fact-checking and debunking, and give them an overview of the issues.
The goal of the workshop is to learn to doubt about information we encounter.

## Presentation of the Associations:
- **Wocsa**: [https://www.wocsa.org/](https://www.wocsa.org/)
  - WOCSA: Improve understanding of cybersecurity issues for all types of audiences, using OpenSource solutions. The Ethical Hacking Workshop focuses on learning defense through the practice of attacks.
- **C’est vrai ça ?**: [https://cestvraica.com/](https://cestvraica.com/)
  - C’est vrai ça ?: Rigorously prove whether a post is true, false, or a mix of both. Analysis and debunks mainly focus on the social network [https://www.linkedin.com/](https://www.linkedin.com/).

## Definitions:
- **What is fake news (infox in French)?**
  - "False or deliberately biased information, spread for example to favor one political party over another, to tarnish the reputation of a person or company, or to contradict established scientific truth, thus contributing to public misinformation."
  - Source: [https://www.pyrenees-atlantiques.gouv.fr/](https://www.pyrenees-atlantiques.gouv.fr/)
- **What is disinformation?**
  - "A particular or continuous action that consists, using all means, of misleading an adversary or encouraging subversion in order to weaken them; the result of this action."
  - Source: [https://www.cnrtl.fr/definition/academie9/désinformation](https://www.cnrtl.fr/definition/academie9/d%C3%A9sinformation)
- **What is misinformation?**
  - "False information that is not shared with the intention to harm." 
  - Source: [https://www.coe.int/fr/web/campaign-free-to-speak-safe-to-learn/dealing-with-propaganda-misinformation-and-fake-news](https://www.coe.int/fr/web/campaign-free-to-speak-safe-to-learn/dealing-with-propaganda-misinformation-and-fake-news)
  - This is what we find most on social networks: posts liked and shared by misinformers... who didn’t pay attention to what they were sharing.
  - "When in doubt, we check... and sometimes, we don’t share."
- **What is malicious information?**
  - "Information based on real facts, used to cause harm."
  - Source: [https://www.coe.int/fr/web/campaign-free-to-speak-safe-to-learn/dealing-with-propaganda-misinformation-and-fake-news](https://www.coe.int/fr/web/campaign-free-to-speak-safe-to-learn/dealing-with-propaganda-misinformation-and-fake-news)
- **What is debunking?**
  - "To ridicule, discredit."
  - Source: [https://www.larousse.fr/dictionnaires/anglais-francais/debunk/574303](https://www.larousse.fr/dictionnaires/anglais-francais/debunk/574303)
  - Here, debunking applies to false information.

## Cognitive Biases:
- Factors in the spread of fake news: [https://fr.wikipedia.org/wiki/Biais_cognitif](https://fr.wikipedia.org/wiki/Biais_cognitif)
- [https://prebunking.withgoogle.com/fr/](https://prebunking.withgoogle.com/fr/) other biases to show "in pictures" here.
- **Sensorimotor biases**: When it comes to sensorimotor processes, we usually talk about illusions rather than biases.
- **Attentional biases**:
  - Attentional bias — having perceptions influenced by one’s own interests.
- **Memory biases**:
  - Recency effect — remembering the last information we were exposed to better.
  - Mere exposure effect — previously being exposed to a person or situation makes it more positive.
- **Judgment biases**:
  - Appeal to probability — tendency to take something as true because it could probably be the case.
  - Appeal to tradition — tendency to consider that the age of a theory or assertion supports its truth.
  - Anchoring bias — influence of the first impression.
  - Automation bias — favoring the machine’s opinion over the human’s.
  - Confirmation bias — tendency to validate one’s opinions with sources that confirm them, and to immediately reject sources that refute them.
  - Dunning-Kruger effect — the least competent in a field overestimate their competence, while the most competent tend to underestimate theirs.
- **Reasoning biases**:
  - Hypothesis confirmation bias — preferring elements that confirm rather than refute a hypothesis.
  - Availability bias — not seeking information beyond what is immediately available.
  - Illusion of clusters — perceiving coincidences in random data.
  - Sunk cost — considering costs already incurred in a decision.

## Key Figures:
- "Reuters Report 2025: Record distrust, emerging chatbots, triumphant social videos" — [https://larevuedesmedias.ina.fr/rapport-reuters-2025-videos-reseaux-sociaux-chatbots-presse](https://larevuedesmedias.ina.fr/rapport-reuters-2025-videos-reseaux-sociaux-chatbots-presse)
  - 29% trust in media (41st worldwide).
  - 44% of 18-24 year olds use social networks and video platforms as their main sources of information.
  - 36% of the French population and 40% of the global population avoid news: the negative effect of news on mood, its exhausting nature, the overabundance of politics or conflicts.
- "2024 European Elections: French particularly vulnerable to disinformation" — [https://www.ipsos.com/fr-fr/europeennes-2024/europeennes-2024-les-francais-particulierement-vulnerables-la-desinformation](https://www.ipsos.com/fr-fr/europeennes-2024/europeennes-2024-les-francais-particulierement-vulnerables-la-desinformation)
  - 74% of respondents believe they can distinguish between true and false information on social networks... but 68% believe that this is not the case for the rest of the French population.
  - 66% of respondents believe at least one of the fake news presented to them.
  - While 61% still trust print newspapers, online media are trusted by only 35% of respondents.
- "Dealing with propaganda, disinformation and fake news" — [https://www.coe.int/fr/web/campaign-free-to-speak-safe-to-learn/dealing-with-propaganda-misinformation-and-fake-news](https://www.coe.int/fr/web/campaign-free-to-speak-safe-to-learn/dealing-with-propaganda-misinformation-and-fake-news)
  - Half of EU citizens aged 15 to 30 say they need information and critical analysis skills to help them combat fake news and extremism in society.

---

# Activity 1: Images FactCheck (30-40 min)

## Objective:
Learn to distinguish real images from those that are edited or generated by AI, using verification tools.
Before the exercise, use this game to see if participants can detect AI-generated images: [https://realitycheckk.com/week1](https://realitycheckk.com/week1) (without tools to help).

## Required Materials:
- Printed image bank (real, edited, AI-generated).
- Tool sheets: Google Lens, TinEye, FotoForensics, Hive Moderation, etc.
- Grids of criteria to evaluate authenticity.

## Tools:
- Search for images already published online: [https://tineye.com/](https://tineye.com/)
- Manipulation and access to metadata: [https://fotoforensics.com/](https://fotoforensics.com/)
- AI image detection: [https://sightengine.com/detecter-images-generees-par-ia](https://sightengine.com/detecter-images-generees-par-ia)
- AI image detection: [https://hivemoderation.com/ai-generated-content-detection](https://hivemoderation.com/ai-generated-content-detection)

## Image Bank:
- **Edited and/or AI photos**:
  - [https://cestvraica.com/debunk/1409119756744790046](https://cestvraica.com/debunk/1409119756744790046) --> [photo_1.webp](./Ressources_:_Part_1_-_Images/photo_1.webp)
  - [https://cestvraica.com/debunk/1408215809490419762](https://cestvraica.com/debunk/1408215809490419762) --> [photo_2.webp](./Ressources_:_Part_1_-_Images/photo_2.webp)
  - [https://cestvraica.com/debunk/1404440017656479874](https://cestvraica.com/debunk/1404440017656479874) --> [photo_3.webp](./Ressources_:_Part_1_-_Images/photo_3.webp)
  - [https://cestvraica.com/debunk/1403360878161690826](https://cestvraica.com/debunk/1403360878161690826) --> [photo_4.webp](./Ressources_:_Part_1_-_Images/photo_4.webp) && [photo_4_bis.webp](./Ressources_Part_1_-_Images/photo_3.webp)
  - [https://cestvraica.com/debunk/1400378195965907055](https://cestvraica.com/debunk/1400378195965907055) --> [photo_5.webp](./Ressources_:_Part_1_-_Images/photo_5.webp) && [photo_5_bis.webp](./Ressources_Part_1_-_Images/photo_3.webp)
  - [https://cestvraica.com/debunk/1375761178529239070](https://cestvraica.com/debunk/1375761178529239070) --> [photo_6.webp](./Ressources_:_Part_1_-_Images/photo_6.webp)
- **Real photos**:
  - [https://cestvraica.com/debunk/1406962306222391390](https://cestvraica.com/debunk/1406962306222391390) --> [photo_7.webp](./Ressources_:_Part_1_-_Images/photo_7.webp)
  - [https://cestvraica.com/debunk/1404926199171387567](https://cestvraica.com/debunk/1404926199171387567) --> [photo_8.webp](./Ressources_:_Part_1_-_Images/photo_8.webp)
  - [https://cestvraica.com/debunk/1404204307498139841](https://cestvraica.com/debunk/1404204307498139841) --> [photo_9.webp](./Ressources_:_Part_1_-_Images/photo_9.webp)
  - [https://cestvraica.com/debunk/1402917917095366722](https://cestvraica.com/debunk/1402917917095366722) --> [photo_10.webp](./Ressources_:_Part_1_-_Images/photo_10.webp)
  - [https://cestvraica.com/debunk/1401806496672514132](https://cestvraica.com/debunk/1401806496672514132) --> [photo_11.webp](./Ressources_:_Part_1_-_Images/photo_11.webp)
  - [https://cestvraica.com/debunk/1401807715235266690](https://cestvraica.com/debunk/1401807715235266690) --> [photo_12.webp](./Ressources_:_Part_1_-_Images/photo_12.webp)
  - [https://cestvraica.com/debunk/1402767921066934272](https://cestvraica.com/debunk/1402767921066934272) --> [photo_13.webp](./Ressources_:_Part_1_-_Images/photo_13.webp)


## Process:
- **Presentation of tools (5 min)**:
  - Show how to use Google Lens, TinEye, ... to verify an image.
  - Explain the limits of each tool (e.g., AI-generated images can fool detectors).
- **Team game (20 min)**:
  - Participants are divided into X teams of two or three people.
  - Each team receives a set of images and must classify them into 2 categories: real, edited/AI-generated.
  - They must justify their choices using the tools and criteria grids. [image_evaluation_grid.pdf](./Ressources_:_Part_1_-_Images/image_evaluation_grid.pdf)
- **Debate and correction (15 min)**:
  - Each team presents its results for the photo.
  - Debate between teams on the choice criteria. What are the limits encountered in using the tools?
  - Explanation of the correct answer with detailed explanations (e.g., metadata analysis, inconsistencies in shadows, number of toes, etc.).

---

# Activity 2: Articles FactCheck (45-60 min)

## Objective:
Develop a methodology for verifying articles and sources, as a team.

## Required Materials:
- 10 varied articles (mix of true, false, and ambiguous), with different levels of difficulty.
- Tool sheets: Vrai ou Faux (FranceInfo), À la Loupe (Toute l’Europe), Decodex (Le Monde), etc.
- Analysis grids: credibility criteria (source, author, date, evidence, bias, etc.).

## Tools:
- Article debunking database: [https://www.hoaxbuster.com/](https://www.hoaxbuster.com/)
- Google Dorking: [https://gist.github.com/sundowndev/283efaddbcf896ab405488330d1bbc06](https://gist.github.com/sundowndev/283efaddbcf896ab405488330d1bbc06)
- Internet (obviously): [google.com](https://google.com)
- Google Fact Check Explorer: [https://toolbox.google.com/factcheck/explorer](https://toolbox.google.com/factcheck/explorer)
- InVID: [https://www.invid-project.eu/](https://www.invid-project.eu/)
- Snopes: [https://www.snopes.com/](https://www.snopes.com/)

## Article Bank:
- **False articles**:
  - [https://cestvraica.com/debunk/1421115781223026761](https://cestvraica.com/debunk/1421115781223026761) --> [article1_steve_jobs.pdf](./Ressources_:_Part_2_-_Articles/article1_steve_jobs.pdf)
  - [https://cestvraica.com/debunk/1420714484833718355](https://cestvraica.com/debunk/1420714484833718355) --> [article2_poison_antidote.pdf](./Ressources_:_Part_2_-_Articles/article2_poison_antidote.pdf)
  - [https://cestvraica.com/debunk/1419277487351009301](https://cestvraica.com/debunk/1419277487351009301) --> [article3_couple_randonneurs.pdf](./Ressources_:_Part_2_-_Articles/article3_couple_randonneurs.pdf)
- **Ambiguous articles**:
  - [https://cestvraica.com/debunk/1419709249419743347](https://cestvraica.com/debunk/1419709249419743347) --> [article4_drainage_postural.pdf](./Ressources_:_Part_2_-_Articles/article4_drainage_postural.pdf) 
  - [https://cestvraica.com/debunk/1419389900012261447](https://cestvraica.com/debunk/1419389900012261447) --> (video)
  - [https://cestvraica.com/debunk/1414296994536755341](https://cestvraica.com/debunk/1414296994536755341) --> [article5_tomate_francaise.pdf](./Ressources_:_Part_2_-_Articles/article5_tomate_francaise.pdf)
- **True articles**:
  - [https://cestvraica.com/debunk/1417979556878356571](https://cestvraica.com/debunk/1417979556878356571) --> [article6_anne_hidalgo.pdf](./Ressources_:_Part_2_-_Articles/article6_anne_hidalgo.pdf)
  - [https://cestvraica.com/debunk/1416129502378987621](https://cestvraica.com/debunk/1416129502378987621) --> [article7_plongeur_decompression.pdf](./Ressources_:_Part_2_-_Articles/article7_plongeur_decompression.pdf)
  - [https://cestvraica.com/debunk/1417557429649936444](https://cestvraica.com/debunk/1417557429649936444) --> [article8_vittel_nestle.pdf](./Ressources_:_Part_2_-_Articles/article8_vittel_nestle.pdf)
  - [https://cestvraica.com/debunk/1416051945558507534](https://cestvraica.com/debunk/1416051945558507534) --> [article9_ia_albanie.pdf](./Ressources_:_Part_2_-_Articles/article9_ia_albanie.pdf)

## Process:
- **Presentation of tools and methodology (10 min)**:
  - Explain how to evaluate an article (who, what, where, when, why, how).
  - Show examples of verification with the mentioned tools.
- **Team game (30 min)**:
  - Two teams compete: each team must identify as many false information as possible in the 10 articles, justifying their choices.
  - They use the grid to justify themselves : [article_evaluation_grid.pdf](./Ressources_:_Part_2_-_Articles/article_evaluation_grid.pdf)
- **Debate and correction (15 min)**:
  - Each team presents its conclusions.
  - Facilitate a debate on the strategies used and the pitfalls encountered.
  - Reveal the correct answers with explanations (e.g., source analysis, cross-checking, expert search).

---

# Conclusion (20-30 min)

## Summary of Learnings:
- Summarize the tools and methods learned.
- Emphasize the importance of vigilance and curiosity.

## Resources to Go Further:
- List of fact-checking sites and tools.
- Books, podcasts, YouTube channels on the subject.

## Evaluation and Feedback:
- Quick questionnaire to assess understanding and appreciation of the workshop.
- Open discussion on complementary workshops (e.g., deepfakes, conspiracy theories).
